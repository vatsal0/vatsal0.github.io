<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Vatsal Baherwani</title>

    <meta name="author" content="Vatsal Baherwani">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Vatsal Baherwani
                </p>
                <p>I'm an undergrad student at the University of Maryland, graduating in 2025. 
                </p>
                <p>This summer I will join the <a href="https://humancompatible.ai/">Center for Human-Compatible AI</a> as a research fellow.</p>

                <p style="text-align:center">
                  <a href="mailto:vatsalbaherwani@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/VatsalBaherwaniCV.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=sAV3TUoAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/vatsalbaherwani">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/vatsal0/">Github</a> &nbsp;/&nbsp;
                  <a href="https://linkedin.com/in/vatsal-baherwani">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://medium.com/@vatsalbaherwani">Blog</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/headshot.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/headshot.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am interested in making AI more accessible, interpretable, and trustworthy. This includes:
                  <ul>
                    <li>Exploring computationally efficient architectures and training methods for LLMs</li>
                    <li>Understanding how and where knowledge is represented in neural networks</li>
                    <li>Ensuring AI models adhere to specific rules and act toward human-aligned interests</li>
                  </ul>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/timesteps.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="/data/MotionDisentanglement.pdf">
              <span class="papertitle">Video Diffusion Models Encode Motion in Early Timesteps</span>
                </a>
                <br>
                <strong>Vatsal Baherwani</strong>, Yixuan Ren, Abhinav Shrivastava
                <br>
                <em>Under Review</em>
                <br>
                <!-- <a href="">project page</a>
                /
                <a href="">arXiv</a> -->
                <p></p>
                <p>
                We show that motion information is independently learned in early timesteps of the diffusion process, prior to the materialization of spatial attributes. We use this insight to present a simple and efficient method for targeted video motion customization.
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/expertapprox.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="/data/DenseBackpropagation.pdf">
              <span class="papertitle">Dense Backpropagation Improves Routing for Sparsely-Gated Mixture-of-Experts</span>
                </a>
                <br>
                Ashwinee Panda*, <strong>Vatsal Baherwani*</strong>, Zain Sarwar, Benjamin Therien, Supriyo Chakraborty, Tom Goldstein
                <br>
                <em>NeurIPS 2024 OPT, ENLSP, Neural Compression Workshops</em>
                <br>
                <!-- <a href="">project page</a>
                /
                <a href="">arXiv</a> -->
                <p></p>
                <p>
                We approximate the dense backward pass of a sparse mixture-of-experts model, leading to improved training stability and performance with negligible overhead.
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/gradcam.png' width="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openreview.net/pdf?id=hQb6ts30wv">
              <span class="papertitle">Racial and Gender Stereotypes Encoded Into CLIP Representations</span>
                </a>
                <br>
                <strong>Vatsal Baherwani</strong>, Joseph Vincent
                <br>
                <em>ICLR 2024 Tiny Paper</em>
                <br>
                <!-- <a href="">project page</a>
                /
                <a href="">arXiv</a> -->
                <p></p>
                <p>
                We demonstrate that image and text embeddings in CLIP exhibit strong biases corresponding to prevalent racial and gender stereotypes.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for his <a href="https://github.com/jonbarron/jonbarron_website">website template</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
